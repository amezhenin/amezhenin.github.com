---
layout: post
title: "Профилирование MongoDB"
description: ""
category: 
tags: [mongodb, profiling, administration]
---
{% include JB/setup %}

<style>
    .fig {
        #text-align: center;
        margin: 10px;
    }
</style>

<link rel="stylesheet" href="/pygments.css"/>

  
  <p class="fig"><img src="/images/monitoring.jpg" alt="monitoring" style="width: 250px;" align='right'/></p>


Порыскав по просторам рунета я, к своему удивлению, обнаружил большие пробелы 
в практических аспектах применения такой замечательно базе данных, как 
[MongoDB](http://www.mongodb.org/). На страницах изданий и интернет ресурсах эта
БД появляется регулярно, есть даже люди, которые давно и успеошно применяют её в смоих проектах, но статьи и советы по правктическому примерению этой базы на 
продакшене впору заносить в красную книгу. Этам постом я попытаюсь пролить свет
на профилирование MongoDB и поделюсь некоторыми набросками кода.
# дать краткое содержание статьи, о чем пойдет речь.


## Логирование
Логи работы системы являются еще одной возможностью проанализировать 
работу БД на предмет потенциальных проблем. Найти лог не сложно, в
`/etc/mongodb.conf` есть соответствующая настройка для этого:
    
    logpath=/var/log/mongodb/mongodb.log

Лог MongoDB хранит множество информации обо всех аспектах работы системы, но 
нас будут интересовать только некоторые записи:

    Wed Jun 26 22:02:06.197 [conn1599] insert test_db.events ninserted:1 keyUpdates:0 locks(micros) w:31 152ms
    Wed Jun 26 22:02:41.183 [conn1598] insert test_db.events ninserted:1 keyUpdates:0 locks(micros) w:33 185ms
    
Такие записи отражают обращения в БД, которые выполнялись более 100 мс. Сюда 
могут входить как команды по изменению данных(*save, insert, update*), так 
и команды по извлечению или агрегации данных(*find, aggregate, mapReduce*), 
например:

    Wed Jun 26 22:05:01.022 [conn1588] command test_db.$cmd command: { aggregate: "events", pipeline: [ ... ] } ntoreturn:1 keyUpdates:0 numYields: 109 locks(micros) r:1788726 reslen:762 921ms
    
В зависимости он того, как организован доступ к БД, в логах могут часто появлятся записи об открытии/закрытии соединения с клиентом и общее число подключений:

    Thu Jun 26 22:46:51 [initandlisten] connection accepted from xxx.xxx.xxx.xxx:56918 #80045 (22 connections now open)
    Thu Jun 26 22:46:51 [conn80043] end connection xxx.xxx.xxx.xxx:51580 (21 connections now open)
    
За логами можно следить в реальном времени, если воспользоваться консольной командой `tail`:

    $ tail -f /var/log/mongodb/mongodb.log

Таким образом можно отслеживать производительность резличных пользовательских сценариев при разработке. 

Логи сильно меня выручали, когда я только начинал разбираться с мониторингом и отладкой MongoDB. Если вы только планируете выводить на продакшен решение на базе MongoDB, изучение логов является обязательным пунктом. Правда, если информации слишком много или нужно проанализировать выполнение запросов за предыдущий период времени, лучше обратиться к другому инструменту. 

## Профилирование
Для целей профилирования работы, в MongoDB существует специальная коллекция 
**system.profile**. В терминологии MongoDB, **system.profile** является ограниченной коллекцией (*capped collection*), потому что её размер ограчен 1Мб. По умолчанию профилирование запросов отключено, и никакой 
информации о работе системы не сохраняется. Из `db.help()` нас будут интересовать две команды:

    db.getProfilingStatus() - returns if profiling is on and slow threshold
    db.setProfilingLevel(level, <slowms>) 0=off 1=slow 2=all

Первая отображает текущия статус профилирования, а вторая помогает его менять. Всего существует три режима, как можно догадаться из подсказки: 

* **0**, профилирование отключено польность. Это режим по умолчанию, если вы еще не успели настроить свою БД, то вы должны увидеть следующее:

   
        > db.getProfilingStatus()
        { "was" : 0, "slowms" : 100 }
    
* **1**, профилирование медленных запросов. Этот режим я использую на продакшене, потому что он позволяет логировать только запросы, выполнявщиеся долше определенного порога(threshold). Когда вы устанавливаете этот режим, второй параметр в `db.setProfilingLevel` становится обязательным и указывает на размер порога срабатывания в миллисекундах. Я использую порог в 100 мс, но это дело вкуса:

        > db.setProfilingLevel(1, 100)
        { "was" : 0, "slowms" : 100, "ok" : 1 }
        > db.getProfilingStatus()
        { "was" : 1, "slowms" : 100 }
        
* **2**, профилирование всех запроса. Хорошо подходит для разработки, но на продакшене использовать нецелесообразно: старые данные профайлерабыстро затираються, а накладные расходы на поддержание столь подробного лога увеличиваются.

        > db.setProfilingLevel(2)
        { "was" : 1, "slowms" : 100, "ok" : 1 }
        > db.getProfilingStatus()
        { "was" : 2, "slowms" : 100 }
        

### Структура документов в system.profile
Все записа профайлера представляют собой обычные документы со следующим набором основных полей:
* **op**, тип операции(*insert, query, update, remove, getmore, command*)
* **ns**, коллекция(а точнее [namespace](http://docs.mongodb.org/manual/reference/glossary/#term-namespace)), над которой производится операция
* **millis**, время выполнения операции в миллисекондах
* **ts**, время(*timestamp*) операции. Большого значения это не имеет, но дата имеено окончания выполнения операции.
* **client**, IP-алрес или имя хоста, с которого мыла отправлена комианда
* **user**, авторизованный пользователь, который выполнил запрос. Если вы не используете авторизацию, то в профайлер будет записана пустая строка. 

В дополнение к основным полям, есть ещё поля, специфические для каждого типа запроса. Для поиска(*find*) это будет сам запрос(*query*), информация о числе просканированных(*nscanned*) и возвращенных(*nreturned*) документов, для изменения(*update*) это будет число обновленных(*nupdated*) и перемещённых на диске(*nmoved*) элементом и т.д. За полным списком полей можно отбратиться к [документации](http://docs.mongodb.org/manual/reference/database-profiler/#output-reference).

Вот пример для вставки(*insert*) документа:

    {
    	"op" : "insert",
    	"ns" : "test_db.test_coll",
    	"ninserted" : 1,
    	"keyUpdates" : 0,
    	"numYield" : 0,
    	"lockStats" : {
    		"timeLockedMicros" : {
    			"r" : NumberLong(0),
    			"w" : NumberLong(46)
    		},
    		"timeAcquiringMicros" : {
    			"r" : NumberLong(0),
    			"w" : NumberLong(424)
    		}
    	},
    	"millis" : 101,
    	"ts" : ISODate("2013-06-28T09:03:21.396Z"),
    	"client" : "127.0.0.1",
    	"allUsers" : [ ],
    	"user" : ""
    }


### Увеличиваем размер system.profile
Выше я упоминал, что данная коллекция имеет ограничение в 1Мб. Это значение можно изменить, если вам кажется что ваам нужет больший объем лога. Сделать это можно следующим: так как **system.profile** является ограниченной коллекцией мы не можем извенить размер зарезервированного под неё места, но мы можем пересоздать её с другими опциями. Вот пример консольных комад:

    db.setProfilingLevel(0)    // останавливаем профилирование
    db.system.profile.drop()    // удалем коллекцию
    // создаем ограниченную коллкуцию с нужными параметрами
    db.createCollection( "system.profile", { capped: true, size:4000000 } )   
    db.setProfilingLevel(1)    // включаем профилирование назад
   
`size` в данном случае это размер в байтах.


### Запросы к профайлеру

К коллекции **system.profile** применимы все те же способы формирования запросов, что и к обычной коллеции. Вот несколько самых ходовых варинтов:
{% highlight javascript %}

    // Вывести все данные в порядке убывания даты создания
    db.system.profile.find().sort({$natural:-1});
            
    // Найти все операции длиннее 5 мс.
    db.system.profile.find( { millis : { $gt : 5 } } );
            
    // Вывести все данные в порядке убывания времини выполнения
    // (самые тяжелые запросы в начале)
    db.system.profile.find().sort({millis:-1});
{% endhighlight %}

Анализ истории помогает выявить и локализовать неэффективные запросы. Для этого стоит регулярно просматривать самые тяжелы операции на предмет ошибки. 

Такой подход я применяю для анализа новых коллекций и пользовательских сценариев, но в определенный момент схема данных и запросы "устаканиваются", а анализ исторических данных начинает показывать одни и те же цифры, в которых сложно заподозрить проблемы. Кароче, со временем этот подход перестает приносить свои плоды, потому что приект/модуль переходит из разработки в стадию поддержки.   

### Продвинутые запросы

На стадии поддержки гораздо важнее видеть общую картину, чем анализировать отдельные запросы. Например, можно следить за количеством "проблемных" запросов(*count*) в интервал времени и средним временем выполнения(*avg_ms*):

    > db.system.profile.aggregate([{$match: {ts:{$gte:ISODate("2013-06-29T00:00:00.000Z"), $lt:ISODate("2013-06-30T00:00:00.000Z")}}}, {$group:{_id:null, count:{$sum:1}, avg_ms:{$avg:'$millis'}}}])
    {
            "result" : [
                    {
                            "_id" : null,
                            "count" : 953,
                            "avg_ms" : 141.8058761804827
                    }
            ],
            "ok" : 1
    }

*Здесь и далее я буду использовать [Aggregation Framework](http://docs.mongodb.org/manual/core/aggregation/) для написания запросов.*    

Несмотря на то, что нет практического смысла в измерении "средней темпераруры по больнице", этот пример демострирует основную идею для постороения различных метрик. 

Давайте для начала сгруппируем по типам операций и добавим еще пару метрик:

    > db.system.profile.aggregate([{$match: {ts:{$gte:ISODate("2013-06-29T00:00:00.000Z"), $lt:ISODate("2013-06-30T00:00:00.000Z")}}}, {$group:{_id:'$op', count:{$sum:1}, avg_ms:{$avg:'$millis'}, min_ms:{$min:'$millis'}, max_ms:{$max:'$millis'}}}])
    {
            "result" : [
                    {
                            "_id" : "update",
                            "count" : 4,
                            "avg_ms" : 124,
                            "min_ms" : 111,
                            "max_ms" : 138
                    },
                    {
                            "_id" : "command",
                            "count" : 15,
                            "avg_ms" : 372.8,
                            "min_ms" : 212,
                            "max_ms" : 3582
                    },
                    {
                            "_id" : "insert",
                            "count" : 868,
                            "avg_ms" : 115.67396313364054,
                            "min_ms" : 100,
                            "max_ms" : 308
                    }
            ],
            "ok" : 1
    }
    
    
Вот это уже интересней, глядя на этот результат можно сделать ряд выводов: 
* основную часть времени база делает **insert** и время выполнения находится в пределах нормы
* **update** происходят редко и не вызывают осложнений
* **command** тоже происходит редко, но среди них есть тяжелые запросы. 

К сожалению, **command** это не какая-то конкретная операция, поэтому, в данном случае придется, вернуться к прошлой технике запросов:

    > db.system.profile.find({op:'command'}).sort({millis:-1}).pretty()
    ...

Можно сгруппировать данные по коллекции:

    > db.system.profile.aggregate([{$match: {ts:{$gte:ISODate("2013-06-29T00:00:00.000Z"), $lt:ISODate("2013-06-30T00:00:00.000Z")}}}, {$group:{_id:'$ns', count:{$sum:1}, avg_ms:{$avg:'$millis'}, min_ms:{$min:'$millis'}, max_ms:{$max:'$millis'}}}])
    
.
    
    db.system.profile.aggregate([{$project: {'ms':{'$subtract':['$millis',{$mod:['$millis', 50]}]}}}, {$group:{_id:'$ms', sum:{$sum:1}}}, {$sort:{_id:1}}]) 
    { 
    	"result" : [ 
    		{ 
    			"_id" : 100, 
    			"sum" : 2993 
    		}, 
    		{ 
    			"_id" : 150, 
    			"sum" : 524 
    		}, 
    ...
    		{ 
    			"_id" : 3600, 
    			"sum" : 1 
    		}, 
    		{ 
    			"_id" : 3650, 
    			"sum" : 2 
    		} 
    	], 
    	"ok" : 1 
    } 



но нам интереснее увидеть это в консоли …

    ['result'].forEach(function(i) { print(i['_id'], '\t',i['sum']); });
    100 	 2981 
    150 	 536 
    200 	 44 
    250 	 10 
    300 	 12 
    350 	 7 
    400 	 1 
    450 	 2 
    500 	 3 
    550 	 2 
    600 	 1 
    650 	 5 
    700 	 1 
    750 	 3 
    800 	 3 
    850 	 3 
    900 	 1 
    1750 	 1 
    3500 	 7 
    3600 	 1 
    3650 	 2 

* общая гистограмма по времени
* разбивка по коллекциям
* как засунуть все в js файл и подключать при старте
* выложить дамп system.profile с инструкцией по восстановлению в пост для тех у кого своей нет. js+dump сохранить в репозитории



## Заключение
В статье не рассмотрены `mongostat`, `mongotop`, `explain`, [db.currentOp](http://docs.mongodb.org/manual/reference/method/db.currentOp/) и
[db.killOp](http://docs.mongodb.org/manual/reference/method/db.killOp/). 
команд по управлению задачами

#### Links
http://docs.mongodb.org/manual/tutorial/manage-the-database-profiler/
http://docs.mongodb.org/manual/reference/command/profile/ 
